\documentclass[galley,usenatbib]{mn2e}
%\documentclass[twocolumn,galley]{mn2e}
%\documentclass[onecolumn,galley,draft]{mn2e}
\usepackage{myaasmacros}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{graphicx}

\def\newblock{\hskip .11em plus .33em minus .07em}

\newcommand{\Glass}{{\sc Glass}}
\newcommand{\PixeLens}{{\sc PixeLens}}
\newcommand{\Rmap}{\ensuremath{R_\mathrm{map}}}
\newcommand{\Rpix}{\ensuremath{R_\mathrm{pix}}}
\newcommand{\M}{\ensuremath{\mathscr{M}}}
\newcommand{\E}{\ensuremath{\mathscr{E}}}
\newcommand{\eps}{\ensuremath{\varepsilon}}

\newcommand{\Eavg}{\ensuremath{\langle \E \rangle}}

\newcommand{\kpc}{\ensuremath{\mathrm{kpc}}}
\newcommand{\Msun}{\ensuremath{\mathrm{M}_\odot}}
\newcommand{\tabref}[1] {Table~\ref{#1}}
\newcommand{\figref}[1] {Figure~\ref{#1}}
\newcommand{\eqnref}[1] {Eq.~(\ref{#1})}
\newcommand{\secref}[1] {\S\ref{#1}}
\newcommand{\appref}[1] {Appendix~\ref{#1}}
\newcommand{\e}[1]{\ensuremath{\times 10^{#1}}}
\renewcommand{\vec}[1]{\ensuremath{\boldsymbol{#1}}}

% From aastex.cls
\newcommand\plotone[1]{%
 \centering
 \leavevmode
 \includegraphics[width={\columnwidth}]{#1}%
}%
\newcommand\plottwo[2]{{%
 \centering
 \leavevmode
 \columnwidth=.45\columnwidth
 \includegraphics[width={\columnwidth}]{#1}%
 \hfil
 \includegraphics[width={\columnwidth}]{#2}%
}}%
\newcommand\plotthree[3]{{%
 \centering
 \leavevmode
 \columnwidth=.30\columnwidth
 \includegraphics[width={\columnwidth}]{#1}%
 \hfil
 \includegraphics[width={\columnwidth}]{#2}%
 \hfil
 \includegraphics[width={\columnwidth}]{#3}%
}}%


\title[\Glass]{Gravitational Lens Recovery with \Glass: How to measure the mass profile and shape of a lens}
\author{%
Jonathan P. Coles 
\and 
Justin I. Read
\and 
Prasenjit Saha 
}

\begin{document}
\maketitle

\begin{abstract}
{\bf JR. Does \Glass\ stand for something?}\\
We introduce a new non-parametric gravitational lens modelling tool: \Glass. \Glass\ uses an adaptive grid of mass pixels to model the lens, searching through hundreds of thousands of models to marginalise over model uncertainties. It is built on a fully modular framework that can support different basis functions, while non-lensing data constraints -- for example stellar mass estimates from stellar population synthesis modelling, or stellar kinematic data -- can also be applied. As a first application, we apply \Glass\ to a suite of dynamically realistic mock N-body data to determine what quality of data -- strong lensing, stellar kinematics, and/or stellar masses -- are required to measure the circularly averaged mass profile of a lens and its shape. Our key findings are as follows: (i) for pure lens data, multiple sources with wide redshift separation give the strongest constraints as this breaks the well-known mass-sheet or steepness degeneracy; (ii) a single quad with time delays also performs well, giving a good recovery of both the mass profile and its shape; (iii) stellar masses -- for lenses where the stars dominate the central potential -- can also break the steepness degeneracy, giving a recovery almost as good as having time delay data or multiple source redshifts; (iv) stellar kinematics are similarly powerful if the data extend beyond the half light radius of the stars $r \gg r_{1/2}$ (required to integrate out the effect of the unknown velocity anisotropy, $\beta(r)$); and (v) if the lensing data already probe the mass profile over the region $r \sim r_{1/2}$, then stellar kinematic data can be used to probe $\beta(r)$ -- an interesting dynamic quantity in its own right. Where information on the mass distribution from lensing and other probes becomes redundant, this opens up the possibility of using strong lensing to constrain cosmological models. We will study this, and present the first results from \Glass\ applied to real data, in forthcoming papers.
\end{abstract}

%(Linear constraints are applied simultaneously with the lens constraints; non-linear constraints are applied in post-processing, with models accepted or rejected based on their likelihood.) 
%These are quantities of key interest for probing the dark matter distribution in galaxies and galaxy clusters to test galaxy formation models and cosmology.

\section{Introduction}\label{sec:intro} %-----------------------------------------------------

{\bf JR. Lots of references missing here. Need to be added. But this should get us started.}\\

Since the discovery of the first gravitational lens
\citep{1979Natur.279..381W}, lensing has become an increasingly important probe
of the distribution of mass in the Universe
\citep{1937ApJ....86..217Z,2012arXiv1206.1225A}. Strong lensing in particular
provides a powerful probe of the mass distribution at the heart of galaxies and
galaxy clusters given good enough data
\citep{2010CQGra..27w3001B,2007ApJ...667..645R,2006ApJ...652L...5S,2009ApJ...690..154S}.
This in turn provides valuable constraints on the nature of dark matter
\citep{2006ApJ...652L...5S,2013ApJ...765...25N}, on cosmological models
\citep{2010Sci...329..924J, 2008ApJ...679...17C}, and on galaxy formation
models \citep{2012MNRAS.424..104L}. To date, some $\sim$400 strong lenses are
known\footnote{{\tt http://admin.masterlens.org/}.}, but with the advent of
large ground and space based surveys, many thousands of lenses are expected to
be discovered over the next ten years \citep{2012arXiv1206.1225A,
2010AAS...21540115M, 2004NewAR..48.1085K}.

The majority of lens modelling efforts to date have focussed on `parametric'
modelling, where simple theoretically motived models are fit using maximum
likelihood methods to the data \citep{2011A&ARv..19...47K, 1993A&A...273..367K,
2010GReGr..42.2151K}. This is useful in that a simple model provides valuable
physical insight. However, as data quality improves and the questions we ask of
these data become more refined, it is important to re-asses the impact of our
model assumptions. `Non-parameteric' methods -- that assume many more
parameters than the available data constraints -- are invaluable in this
respect. In non-parametric mass modelling, the lens inversion problem is
deliberately chosen to be under-constrained
\citep{1997MNRAS.292..148S,2005MNRAS.360..477D,2010ApJ...723.1678C,2006MNRAS.367.1209L,2013arXiv1304.2393S}.
Instead of finding one `best-fit' model, we must then search for many models
consistent with the data, exploring degeneracies between different but
plausible\footnotemark\ mass models
\citep{2000AJ....120.1654S,2006ApJ...653..936S,2008MNRAS.386..307L}. The key
advantages of non-parametric modelling are that we can: (i) explore model
degeneracies and marginalise over them; and (ii) we can determine what type and
quality of data (including data from stellar population synthesis modelling,
stellar kinematics, or other independent probes of the mass) are required to
measure parameters of interest. 

\footnotetext{The word {\it plausible} encodes the key hidden gremlin in
non-parametric methods: constraints extra to the available data (priors) are
typically required on the solution space in order to make it finite. However,
even rather restrictive priors are far less restrictive than the implicit
constraints inherent in parametric mass modelling.}

In this paper, we use a new non-parametric strong lens modelling framework
\Glass\ to determine what quality and combination of lensing, stellar mass, and
stellar kinematic constraints best constrain the projected mass profile and
shape of a gravitational lens. This is particularly timely given the coming
explosion in strong lensing and complimentary data. Some significant work has
already proceeded in this direction in the literature.
\citet{2007ApJ...667..645R} were the first to test the recovery of strong
lensing surface density profiles using mock data generated from N-body models
{\bf JR. Is this true?}. They found that when including time delays, circularly
averaged surface density distributions can sufficiently well-recovered to make
interesting comparisons with theoretical models\footnote{Cosmological
parameters, however, are more sensitive. \citet{2007ApJ...667..645R} found that
over-restrictive model assumptions can lead to significant bias on the Hubble
parameter, $H_0$, for example, explaining earlier tensions reported in the
literature \citep[e.g.][]{2002astro.ph..4043K}.}. Since then, several groups
have used N-body mock data to explore the fidelity of strong lensing
reconstruction. \citet{2007MNRAS.380.1729L} explore the recovery of N-body
models using a new non-parametric genetic algorithm. Such comparisons were key
in the development of their novel `null-space' constraint that includes
information about where there a no images in addition to where there are
observed ones. XXX did YYY, finding ZZZ {\bf JR. I am sure there are many more
references that ought to be added here.}. Here, we expand on these earlier
works by considering not only the circularly averaged surface density profile
of a lens, but also its shape, higher order measures of the mass recovery (a
pixel-by-pixel comparison), and by considering the utility of wrapping in
constraints from stellar mass estimates, or stellar kinematics. 

We use a new lensing tool, \Glass\, that uses an adaptive grid of mass pixels
to model the lens, generating thousands of models to marginalise over
uncertainties. \Glass\ shares some heritage with an earlier code, \PixeLens\
\citep{1997MNRAS.292..148S,2008ApJ...679...17C}, but differs in several
important respects: 

\begin{enumerate} 
\item it uses a significantly improved sampling strategy that is both faster and results in significantly smaller errors \citep{2012MNRAS.425.3077L};
\item it is built on a fully modular framework that can support different basis functions;
\item non-linear constraints can be applied in post-processing (for example, filters to remove models with spurious additional images or models inconsistent with stellar dynamics data are already implemented);
\item the stellar mass (if known) can be applied as a prior; and
\item adaptive resolution can be used in regions of interest. 
\end{enumerate}

This new functionality allows us to use model strong lens systems while
wrapping in additional data constraints. Linear constraints -- like the stellar
mass -- are applied simultaneously with the strong lensing constraints;
non-linear constraints are applied in a post-processing step, where models are
rejected using a likelihood analysis. This latter was prohibitively expensive
with \PixeLens\ as only up to $\sim$1000 models could be generated in a
reasonable time. With \Glass, we can routinely generate hundreds of thousands
of models such that we can afford to discard some if they are inconsistent with
independent data. In this first application of \Glass, we apply it to a suite
of dynamically realistic mock N-body data to test the recovery of the
circularly averaged mass profile of a lens and its shape. We will consider
using strong lensing as a cosmological probe, and present the first results
from \Glass\ applied to real data, in forthcoming papers.

This paper is organised as follows. In \secref{sec:theory}, we review the basic
lensing, stellar population synthesis, and Jeans mass modelling theory we will
need. We present some simple back-of-the-envelope calculations that illustrate
what type and quality of data we are likely to need to measure mass profiles
and shapes. In \secref{sec:glass}, we describe the \Glass\ lens inversion
algorithm and its stellar kinematic post-processing module. In
\secref{sec:mockdata}, we describe our mock N-body data and our ray tracing
algorithm used to generate the images. In \secref{sec:results}, we present our
results from applying \Glass\ to these mock data. Finally, in
\secref{sec:conclusions} we present our conclusions. 

\section{Theoretical Background}\label{sec:theory} %-----------------------------------------------------

\subsection{Lensing basics}\label{sec:lensing_basic} %-----------------------------------------------------

The lens equation:
%
\begin{equation}
\vec\beta = \vec\theta - \frac{D_{LS}}{D_S}\vec\alpha(\vec\theta)
\label{eqn:lens_equation}
\end{equation}
%
maps an observed image position $\vec\theta$ to a source position $\vec\beta$
via the correction factor \citep[e.g.][]{1992grle.book.....S}:
%
\begin{equation}
\vec\alpha(\vec\theta) = \frac{4GD_L}{c^2} \int \Sigma(\vec\theta')\frac{(\vec\theta - \vec\theta')}{\ |\vec\theta - \vec\theta'|^2}d^2\vec\theta'
\end{equation}
%
which accounts for the gravitational lensing effect of an intervening mass
(where $G$ is Newton's gravitational constant, and $c$ is the speed of light).
For our purposes we make use of the thin mass sheet approximation and assume
that the lensing mass is infinitely thin compared with the distance between the
source and the lens $D_{LS}$ and the lens and the observer $D_{L}$. These are
angular diameter distances where $D_* = (c/H_0)d_*$ and $d_*$ is a
dimensionless number that depends on cosmology.  The lens can then be thought
of as a projected surface density $\Sigma$ which diverts the path of a photon
instantaneously through the bending angle $\vec\alpha$.

Since we will later want to model the density distribution with a computer it
will be convenient to choose units that make the relevant quantities of order
unity.  We therefore measure lengths in light years, time in years, positions
in arcseconds, and choose $c=1$ and $4\pi G = N^2$, where $N^2 \equiv 206,265$
arcsec/rad. The mass unit is then $11.988\ \Msun$. It will also be useful to
define a proxy to the Hubble constant $\nu \equiv N^2 H_0$.

One way to understand the lens equation is via Fermat's principle. We can think of light as travelling only 
along extremum paths; lensed images only occur at the extrema of a virtual photon {\it arrival time surface} 
\citep{1986ApJ...310..568B}. The arrival (or travel) time $t$ of a virtual photon depends not only on the geometric
path it takes, but also on the general relativistic gravitational time dilation
due to the lens at a redshift of $z_L$.  In its complete form, with all units
and cosmology included we can write the arrival time as \citep{1986ApJ...310..568B}:
%
\begin{eqnarray}
N^2ct(\vec\theta) & = & (1+z_L)\frac{D_{L}D_{S}}{D_{LS}}\frac12 |\vec\theta - \vec\beta|^2 \nonumber \\
& & - (1+z_L)\frac{4GD_{L}^2}{c^2}\int \Sigma(\vec\theta') \ln |\vec\theta-\vec\theta'| d^2\vec\theta'
\label{eqn:full_arrival_time}
\end{eqnarray}
%
where the factor of $D_L^2$ in the second term comes from the fact that $\Sigma$
has units of \Msun/lyr$^2$. We can clean this up by writing down a dimensionless time
delay:
%
\begin{eqnarray}
\tau & = & \left[(1+z_L)D_{L}\right]^{-1}ctN^2 \nonumber \\
& = & \left[ (1+z_L) \frac{c}{H_0}d_L\right]^{-1}ctN^2 \nonumber \\
& = & \left[ (1+z_L) d_L\right]^{-1}\nu t
\label{tau}
\end{eqnarray}
%
in terms of our previous definitions. If we
further define a dimensionless density:
%
\begin{equation}
\kappa_\infty = \frac{4\pi G}{c^2}\frac{c}{H_0}d_L\Sigma
              = \frac{d_L}{\nu}\Sigma
\end{equation}
%
and a lensing potential:
%
\begin{equation}
\psi(\vec\theta) = \frac1\pi \int \kappa_\infty(\vec\theta') \ln|\vec\theta - \vec\theta'| d^2\vec\theta'\
\label{lensing potential}
\end{equation}
%
we can express \eqnref{eqn:full_arrival_time} very compactly as:
%
\begin{equation}
\tau(\vec\theta) = \frac12 \xi |\vec\theta-\vec\beta|^2 - \psi(\vec\theta)
\label{arrival time}
\end{equation}
%
where $\xi \equiv D_{S}/D_{LS}$. We explicitly write $\kappa_\infty$ to remind ourselves
that there is no source distance factor involved. This will be useful later when we consider
multiple sources.

If we think of $\tau$ as a surface then images will be observed wherever
$\nabla \tau = 0$. In other words, images obey Fermat's principle and appear at
extremums of the surface. Note that $\nabla \tau$ is just \eqnref{eqn:lens_equation} or:
\begin{equation}
  \xi \vec\beta = \xi \vec\theta - \frac 1\pi\int \kappa_\infty\frac{(\vec\theta - \vec\theta')}{\ |\vec\theta - \vec\theta'|^2}d^2\vec\theta'
\end{equation}

The only observables from \eqnref{arrival time} are the image positions, and
perhaps the stellar contribution to $\kappa_\infty$.  If the source object is
variable, however, then the observed light curves of each image will be
identical, but possibly shifted in time due to the different arrival times.
The time difference between identical portions of the light curves is called
the time delay $\Delta t$ between images.  Using \eqnref{tau} the time delay
$\Delta t_{21}$ between two images $\vec\theta_1$ and $\vec\theta_2$, where $\vec\theta_2$
arrives after $\vec\theta_1$, is $\Delta t_{21} = \Delta \tau_{21}(1+z_L)d_L /
\nu$. If $\beta$ and $\kappa_\infty$ were known exactly this would allow one
to precisely infer the Hubble constant. However, the source position is not
observable and the density distribution is highly degenerate.

\subsection{Degeneracies}\label{sec:degen} %-----------------------------------------------------

The trouble with solving the lens equation for the mass distribution is that the solutions are non-unique and degenerate -- many different solutions can give a statistically good reproduction of the data. To see why this is, it is instructive to simplify \eqnref{eqn:lens_equation} for a circularly symmetric lens: 
%
\begin{equation}
\vec\beta = \vec\theta - \frac{\theta_E^2}{\theta^2}\vec\theta
\label{eqn:lens_equation_circ}
\end{equation}
%
where $\theta = |\vec\theta|$, $\theta_E^2 = \frac{D_{LS}}{D_S D_L} \frac{4 GM(<\theta)}{c^2}$ is the Einstein radius, and $M(<\theta)$ is the mass enclosed within the images. 

For sources on-axis (\vec\beta\ = \vec0), the images split into a degenerate Einstein ring with $\theta = \theta_E$. Even in this situation of maximal information (since the source position $\vec\beta$ cannot typically be known), there is a trivial degeneracy between $M(<\theta_E)$ and the angular diameter distances that depend on cosmological parameters (most strongly on the Hubble constant, $D_{L,S} \propto 1/H_0$). For fixed cosmology, a single source splitting into images in the most ideal situation gives us only an enclosed mass. This `steepness' degeneracy (also known as the mass-sheet degeneracy) generalises to the non-circularly symmetric case (CITES). Thus, to measure the mass profile of a lens, we require more information. This can come in the form of another source at different redshift that has its own Einstein radius, giving $M(<\theta_E')$. Or it can come in the form of additional constraints like time delay data between the images, stellar mass estimates from stellar populations synthesis modelling (CITE), stellar kinematics (CITE), or similar. However, even with further information, higher order degeneracies remain. XXX showed that there is a monopole degeneracy that allows additional mass to be deposited in-between images without any optical effect, while YYY find twisting degeneracies exist if ZZZ. These higher order degeneracies have a larger effect on shape measurement than the mass profile but remain largely uncharacterised in the literature. Further degeneracies enter also if there is a strong {\it external} field acting on the lens -- for example from a larger group or cluster environment within which the lens sits (CITES); this {\it shear term} can, in principle, however, be constrained by data (CITES). In \secref{sec:results}, we will use \Glass\ to determine how well such degeneracies can be broken by data of ever-increasing quality to measure the mass profile and shape of a lens. We assume throughout that the shear is negligible. 

\section{Numerical Methods}\label{sec:glass}

\subsection{A new lens modelling framework: \Glass}

\Glass\ is an evolution of the concepts employed by the free form modelling tool
\PixeLens\ but completely rewritten in Python and C. The key improvements are:
%
\begin{enumerate}
  \setcounter{enumi}{0}
  \item A modular framework allows new priors to be added and modified easily.
\end{enumerate}
%
Each prior is a simple function that adds linear constraints that operate on either
a single lens object or the entire ensemble of objects. \Glass\ comes with a number
of useful priors, but a user can write their own in the input file.
%
\begin{enumerate}
  \setcounter{enumi}{1}
  \item The basis functions approximating a model can be changed. 
\end{enumerate}
%
\Glass\ currently describes the lens mass as a collection of pixels, but the code
has been designed to support alternative methods. In particular, it is planned
to develop a module using Bessel functions. This will require a new set of 
priors that operate on these functions.
%
\begin{enumerate}
  \setcounter{enumi}{2}
  \item Non-linear constraints can be imposed in an automated post-processing step. 
\end{enumerate}
%
Once \Glass\ has generated an ensemble of models given the linear constraints, any number
of post processing functions can be applied. Not only can these functions be used to
derive new quantities from the mass models, they can also be used as a filter to 
accept or reject a model based on some non-linear constraint. The plotting functions
within \Glass\ will correctly display models that have been accepted or rejected.
%
\begin{enumerate}
  \setcounter{enumi}{3}
  \item The central region can be have a higher resolution to capture steep models. 
\end{enumerate}
%
By default, the mass distribution of the lens is described by uniform grid. However,
in the central region of a lensing galaxy where the mass profile may rise steeply,
a higher resolution can be specified that only applies to the inner pixels. These
pixels are subdivided into a smaller grid.
%
\begin{enumerate}
  \setcounter{enumi}{4}
  \item Stellar density can be used as an additional constraint.  
\end{enumerate}
%
The mass in inner regions of galaxies is often dominated by the stellar component
which one can estimate using standard mass-to-light models. This data can be added
to the potential as described later in \secref{stellar mass}. By using the stellar
mass one can place a lower bound on the mass and help constrain the inner most
mass profile.
%
\begin{enumerate}
  \setcounter{enumi}{5}
  \item Point or extended mass objects can be placed in the field.
\end{enumerate}
%
\PixeLens\ only allows for a shear term to be added to the potential (as shown
later in \eqnref{shear}) to account for mass external to model region. This
is useful to capture the gross effects of a distant neighbour. \Glass\ also
has a shear term but additional allows for additional analytic potentials to
be included. This can be used to model substructure or multiple neighbors close
to the main lens. The substructure may have only a small effect if the lens is
a single galaxy, but if the lens is group then a potential can be added for
each of the galaxies.
%
\begin{enumerate}
  \setcounter{enumi}{5}
  \item A new uniform sampling algorithm for high dimensional spaces.
\end{enumerate}
%
At the heart of \Glass\ lies a new algorithm for sampling the high dimensional
linear space that represents the modelling solution space. This algorithm was
described and tested in \cite{}. \Glass\ is also multi-threaded allowing it to
run efficiently on many-cored machines.  The software is freely available for
download. One interesting aspect is that the input files are themselves Python
programs. This allows a large amount of sophistication in setting up a lens at
runtime and also allows \Glass\ to be used as an external library from another
user written program.

\subsection{Discrete models}

For this paper we will restrict ourselves to using the pixelated basis set that
has been employed in previous work and is implemented in \PixeLens. Here we
will briefly review the main ideas. The algorithm for generating models in
\Glass\ samples a convex polytope in a high dimensional space whose interior
points are solutions to the lens equation and satisfy other physically
motivated linear priors (the sampling algorithm in \Glass\ is not the same as
employed in \PixeLens).  We therefore formulate all of our equations as
equations linear in the unknowns. We describe the density distribution $\kappa$
as a set of discrete grid cells or pixels $\kappa_i$ and rewrite the potential
(\eqnref{lensing potential}) as
%
\begin{equation}
  \psi(\vec\theta) = \sum_n \kappa_n Q_n(\vec\theta)
  \label{discrete potential}
\end{equation}
%
where the sum runs over all the pixels and $Q_n$ is the integral of the logarithm
over pixel $n$. The exact form for $Q$ is described in \appref{Q derivation}.
We can find the discretized lens equation by simply taking the gradient of the
above equations. 

The pixels only cover a finite circular area with physical radius $\Rmap$ and
pixel radius $\Rpix$ centered on the lensing galaxy. To account for any global
shearing outside this region from, e.g., a neighboring galaxy, we also add to
\eqnref{discrete potential} two shearing terms
%
\begin{equation}
\label{shear}
\gamma_1(\theta_x^2 - \theta_y^2) + 2\gamma_2\theta_x\theta_y\quad.
\end{equation}
%
We can continue adding terms to account for other potentials. For instance,
we may want to impose a base potential over the field, or add potentials
from the presence of other galaxies in the field. \Glass\
already includes potentials for a point mass or an exponential form, but custom
potentials are straightforward to add and can be included directly in the input file.
If the stellar density has been estimated we can use this as a lower bound
where the stellar potential is a known constant of the form \eqnref{discrete
potential}.

%
%\begin{equation}
  %\psi^*(\vec\theta) = \sum_n \kappa^*_n Q_n(\vec\theta)\quad.
%\end{equation}
%

Unfortunately, the lens equation and the arrival times alone are not enough to form a
closed volume in the solution space. We have not imposed any strong constraints
on the density even so much as to ensure that it is non-negative everywhere. We
must therefore provide additional linear constraints so that we only sample
physical models. The explicit implementation for these priors has been
explained in \cite{}, but can be summarized as
\begin{enumerate}
\item The density must be non-negative everywhere.
\item The density profile must have a slope everywhere $\le 0$. This prevents hollow rings.
\item The local gradient everywhere must point within $45^{\circ}$ of the center.
\item Density variations must be smooth.
\item Image parity is enforced.
\item The density is radially symmetric. (Optional)
\end{enumerate}

In the simplest form, a single model for a lens is a tuple $\M = (\vec\kappa,
\beta, \gamma_1, \gamma_2)$. A single model represents a single point in the
solution space polytope. Using the MCMC sampling strategy described in \cite{}
we uniformly sample this space. Collectively, the sampled models are referred
to as an ensemble $\E = \{\M_i\}$, where we usually generate $\sim$1000 models. We
will typically show the ensemble average $\Eavg$ in the plots to
follow.

\subsection{Removing models with extra images}



\subsection{A post-processing module for stellar kinematics}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Raytracing}
\label{Raytracing}
\Glass\ can also determine the position of images and time delays from 
particle-based simulation output given a source position $\vec\beta$. This is
used to generate the lens configurations used in the parameter study.  The
particles are first projected onto a very high resolution grid representing the
lens plane. The centers $\vec\theta_i$ of each of the grid cells are mapped
back onto the source plane using \eqnref{eqn:lens_equation}. If the location on
the source plane $\vec\beta_i$ is within a user specified
$\eps_\mathrm{accept}$ of $\vec\beta$ then $\vec\theta_i$ is 
accepted and further refined using a root finding algorithm until the distance
to $\vec\beta$ is nearly zero. If multiple points converge to an
$\eps_\mathrm{root}$ of each other then only one point is taken.  Care must be
taken that the grid resolution is high enough that the resulting image position
error is below the equivalent observational error. Time delays are then
calculated in order from the arrival time at each image (\eqnref{tau}).

\section{The mock data}\label{sec:mockdata}

We now present a study of four mock galaxies with known analytic forms to
confirm that \Glass is able to correclty recover the mass profile.

\subsection{Setting up the triaxial N-body mocks}

The four mock galaxies we consider have been designed to test our recovery
procedure. They are two component models where the dark matter and stellar
profiles are allowed to be steep and shallow.  The enclosed mass in all cases
is fixed at $M(a_\star)= 1.8\e{10}$ at the scale radius $a_\star=2$ kpc. These
values were chosen to closely resemble B1115. We therefore place the galaxy at
a redshift of $z_L = 0.31$ for lensing.  Throughout, we assume a cosmology
where $H_0^{-1}=13.7$ Gyr, $\Omega_M=0.28$, and $\Omega_\Lambda=0.72$. The
critical density is $\kappa_\mathrm{crit}\sim 1.8\e{9}$\Msun/kpc$^2$.

The galaxies were
first generated as three dimensional particle distributions with the
tool DEHNEN-TOOL. Each component follows the profile
\begin{equation}
\rho(r) = \frac{M}{4\pi a^3}(3-\gamma){(r/a)^{-\gamma}(1 + r/a)^{\gamma-4}}
\label{Dehnen profile}
\end{equation}
where $\gamma$ is the profile index and $a$ is the scale radius.  In the
case $\gamma=1$ this is the Hernquist profile.  The four combinations of
profile indices are shown in \tabref{mock galaxy params}.  Note that two of
the galaxies have $\gamma_\mathrm{DM}=1$. While we know from simulations that a
more accurate approximation would be an NFW or Einasto profile we are not
probing the outer regions of the halo where the difference would be most
extreme.  The Hernquist profile is easier to generate as it has finite mass.

\begin{table}
\begin{tabular}{cllllllll}
Galaxy & $\gamma_\star$ & $M_\star$ & $\gamma_\mathrm{DM}$ & $M_\mathrm{DM}$ & $\Rmap$ & Notes\\
\hline
AA & 1 & 4 & 0.05 & $11^{2.95}$ & 50 kpc & \\
AC & 1 & 4 & 1 & $11^2$ & 50 kpc & \\
BB & 1.5 & $2^{1.5}$ & 0.16 & $11^{2.84}$ & 50 kpc & \\
BC & 1.5 & $2^{1.5}$ & 1 & $11^2$ & 10 kpc & 
\end{tabular}
\caption{Profile parameters for the four mock galaxies. The resulting profiles only roughly follow
\eqnref{Dehnen profile} because the galaxies are triaxial. Masses are in units of $1.8\e{10}\Msun$. The scale lengths for
all lenses are $(a_\star,a_\mathrm{DM})=(2,20)$ kpc and by definition
$M_\star(a_\star) = M_\mathrm{DM}(a_\star) = 1$. $\Rmap$ is the 2d projected radius used to generate the lens configurations.}
\label{mock galaxy params}
\end{table}

\begin{figure}
\plotthree{MockGalProfile-a.pdf} {MockGalProfile-b.pdf} {MockGalProfile-c.pdf}
%\plotone{MockGalProfile-a.pdf} \plotone{MockGalProfile-b.pdf} \plotone{MockGalProfile-c.pdf}
\caption{
\textbf{(Left)} 
Three-dimensional density of the galaxies showing the stellar, dark matter,
and total densities with dotted, dashed, and solid lines, respectively. The
grey lines show the analytic forms from \eqnref{Dehnen profile}. 
\textbf{(Middle)} 
The radially averaged two-dimensional projected density.
The critical density for lensing at $z_L=0.31$ is $\kappa_\mathrm{crit}\sim 1.8\e{9}$\Msun/kpc$^2$.
\textbf{(Right)}
The enclosed projected mass.
}
\label{mock galaxies}
\end{figure}

In \figref{mock galaxies} we show the 3D radial density, 
the 2D projected density, and the 2D enclosed mass for each
galaxy. Solid lines represent the total mass, dashed lines the dark 
matter, and dotted lines the stellar mass. The projected plot has
been normalized to the critical density.

\subsection{Lens configurations} %--------------------------------------------------------------

For each of the four galaxies, we used the raytracing feature of \Glass\
described in \secref{Raytracing} to construct 12 lensing scenarios:

\begin{enumerate}
\item One double and one extended double.
\item One quad and one extended quad.
\item Two 2-source quads with varying redshift contrast.
\end{enumerate}

The extended configurations use extra sources to generate extra images that
simulate an arc. \figref{config ex.} shows the configuration for the extended
quad.

Each of these configurations were modelled with and without time delays and with
and without a central image. We assumed for all our tests that the lensing mass
was radially symmetric. By construction, this is known to be true and this is
most often the case with real galaxies, unless there is an obvious observed
asymmetry. The central pixel was refined into a further nine pixels to capture
any steep rise in the profile. Two of the four mock galaxies have a steeply rising
inner profile.

\section{Results}\label{sec:results}

\figref{reconstruction} shows a typical reconstruction of a
lens. The far left plot shows the ensemble average arrival time surface with
image marked as circles and the inferred source position as a diamond. The
center plot shows the radial density profile. The error bars cover the full
range of models generated by \Glass. The true density profile from the mock
data is also plotted for comparison. The vertical lines mark the radial
position of the images. The final plot on the right is of the enclosed mass. As
expected the error bars are smallest in the region of the images where the most
information about the lens is present. The dip in the profile at the end of the
profile is due to the cut off in mass in the lensing map. This is of little
importance, though, as there is no lensing information there.

\begin{figure}
\plotthree{BCQuadR1a_TmS-a.pdf}{BCQuadR1a_TmS-b.pdf}{BCQuadR1a_TmS-c.pdf}
\caption{A typical reconstructed lens. Here we present a single quad lens from 
the BC mock galaxy.
\textbf{(Left)}
The arrival time surface. 
\textbf{(Middle)}
The surface density. The magenta curve represents the dark matter component,
the yellow curve the stellar component, and the blue curve is the sum of the two.
The black curve comes from the original mass model used to create the lens.
The green vertical lines mark the radial positions of the images. The higher
resolution feature of \Glass\ has been used on the central pixel allowing the
steep profile to be captured.
\textbf{(Right)}
The cumulative mass.}
\label{reconstruction}
\end{figure}

The main results from modelling these different configuration are shown black in
\figref{main results}. Each subplot corresponds to a different galaxy and
the vertical axis shows the range of quality.  The quality of a
model $\M_i$ by comparing the recovered density profile $\rho_\M(r)$ against
the profile of the mock galaxy $\rho_G(r)$.  In particular, the plots show the
RMS quantity
%
\begin{equation}
  \chi_i = 100 \times \sqrt{\frac{\int_r (\rho_{\M_i}(r) - \rho_G(r))^2}{\int_r \rho_G(r)^2}}
  %\chi_i = \frac{\sum_r (\rho(r)_{\M_i} - \rho(r)_G)^2}{\sum_r \rho(r)_G^2}
\end{equation}
%

\begin{figure}
\plottwo{AAchi2_profile.pdf}{BBchi2_profile.pdf}

\plottwo{ACchi2_profile.pdf}{BCchi2_profile.pdf}
\caption{The main results showing the quality of model recovery. Each panel corresponds to 
the named mock galaxy, whose parameters are listed in \tabref{mock galaxy params}. Within
each panel are six groups of results for each of six lens morphologies. Each morphology
considered the presence of time delays and a central image. The black markers are for tests
that did not include the stellar mass as a lower bound constraint, while the red markers
indicate where the stellar mass has been given.}
\label{main results}
\end{figure}

\begin{figure}
\plotone{BCarrival_surfaces}
\caption{The lens configurations for the six test cases using the BC mock galaxy. Here,
the central image is shown, although not all tests include it. The central image belongs
to only one set of images to avoid overconstraining the models. Similar colors group
images that share a common source. In the case of the extended image systems the source
is at the same redshift, while the redshift is varied between the systems in the 
ZConstrast cases. Grey circles are a visual aid to help determine radial separation
between images. The axes are measure in arcseconds.}
\label{arrival surfaces}
\end{figure}

The morphological complexity increases from left to right within each plot. As
a result, there is a general trend for the reconstruction quality to increase
(and for $\chi$ to decrease). By adding more measurable information to each
configuration the quality can also be affected. When both time delays and a
central image are present the quality is highest. A double is known to provide
very little constraint on the mass distribution. This is particular evident in
galaxies AC and BC where the mass profile is steepest and the reconstruction of
the double is poorest. However, the addition of an arc is sufficient to correct
this.

\subsection{Stellar mass}
\label{stellar mass}

The previous tests have been conducted to show that \Glass\ performs as expected.
Here, we present a novel constraint that can significantly improve the models. 
The stellar mass distribution is a lower bound on the total mass and in the
central region of a galaxy is also the dominant component. It can therefore be
used to constrain the innermost profile. We took the stellar mass directly from
the generated galaxies and projected the particles onto the pixels. \Glass\
also offers an option to interpolate any map of stellar mass (e.g., from an
observation) onto the pixels. The linear constraint is added to \Glass\ by
writing $\kappa_n = \kappa_{dm,n} + \kappa_{s,n}$ as the sum of the
dark matter and stellar mass components in the potential (\eqnref{discrete
potential}). Since each $\kappa_{s,n}$ is just a constant we do not add new,
separate equations for each pixel. 

With the stellar mass lower bound, the improvement of the reconstruction
quality shown in \figref{main results} is quite dramatic for the
steepest mock galaxies (AC and BC). This is because these models are dominated
by stars in the inner region. The other two galaxies are unaffected because the
models were already well modeled by the dark matter alone.

\subsection{Velocity anisotropy}

In addition to the lens model aspects, \Glass\ can also run post processing
routines to analyze each model as it is produced. We have developed a number of
routines for fitting analytic models to the lensing mass profiles. One in
particular deprojects the 2d profile assuming a Hernquist profile for the
light. By fixing the velocity anisotropy $\beta$ we can determine the velocity
dispersion of the model. Of course, the true velocity dispersion is known for
the mock galaxies and we can compare our method to those measurements.  In
\figref{sigma-beta} we plot the recovered velocity dispersion for $\beta=0$ and $\beta=1$
over a range of aperture sizes for the BC Quad with time delays and stellar
mass. The stellar half mass radius is plotted in yellow and the Einstein radius
in black. For this configuration the two radii are well separated. This plot
demonstrates that the velocity anisotropy can be inferred by combining lens
modelling and independent velocity dispersion measurements. The lens breaks
the anisotropy degeneracy at a given aperture.

\begin{figure}
\plotone{BCQuadR1a_TmS-sb.pdf}
\caption{Estimated velocity dispersion as a function of the aperture size. The
single quad lens model for the BC mock galaxy was deprojected and the mass
profile fit assuming a Hernquist profile for the light. The top curve (blue)
assumes a velocity anisotropy $\beta=1$, while the lower curve (green)
assumes $\beta=0$. Given an independent estimate of the velocity dispersion,
lensing can be used to place constraints on the velocity anisotropy.}
\label{sigma-beta}
\end{figure}

%\subsection{Velocity dispersions}
%
%\begin{itemize}
%\item Can they predict radial profiles?
%\item Can we constrain lensing models from predicted velocity dispersions?
%\item Use a constructed spherical halo G2 following a $\rho \propto r^{-\gamma}$ profile with stellar halo same as G1.
%\item Vary $z$ of the halo, possibly orientation.
%\item Should be able to recover $\gamma$ very well.
%\item Use G1. Show problems with recovering $\gamma$.
%\end{itemize}

%\subsection{With/without time delays and central image} %--------------------------------------------------------------

%We also considered the effect of having time delays or a central image. The
%central image is usually highly demagnified and obscured by the lensing galaxy,
%but in clusters the central image is observable. In this case we can imagine
%the galaxies to be clusters since the problem is scale-free. A recontruction of
%AASingleQuadR1a\_Tm is shown in \figref{AASingleQuadR1a_Tm}. The suffix denotes
%which combination of time delays (T) and central image (M) was used. An
%uppercase letter indicates the feature is turned on, and a lowercase letter
%that it is turned off.

\section{Conclusions}\label{sec:conclusions}

extensible framework                                                       

accurate reconstructions through better sampling                           

where stellar mass significant, including it greatly improves accuracy 

breaking the vdisp/anisotropy degeneracy.

\appendix

\section{Raytracing convergence test}
Raytracing is sensitive to the map area and resolution set by $\Rmap$ and
$\Rpix$.  In the left panel of \figref{raytracing convergence tests} we compare
the change in time delays as we increase $\Rmap$.  The image system is a quad
with the central maximum image. When the projected mass begins to fall off the
time delays stabilize. In the right panel we see the effect of changing the
resolution of the map.  Increasing the resolution allows for more accurate
placement of the images and after about $\Rpix=40$ the image positions change
by less than 0.04 arcsec. The one image that continues to change is near to a
caustic.  

\begin{figure}
\plottwo{tdconv_pr45.pdf}{imgpos_conv_mr20.pdf}
\caption{(left) Test for predicted time delay convergence as $\Rmap$ changes.
$\Rpix=45$. After about $\Rmap=20$ most of the asymmetric mass is in the map.
(right) Test for predicted image position $\theta$ convergence as $\Rpix$
changes. $\Rmap=20$ arcsec.}
\label{raytracing convergence tests}
\end{figure}

\section{Derivation of pixelated density coefficients}
\label{Q derivation}
When the lens plane is pixelized we need a discrete form of the integral
%
\[\int \kappa(\vec\theta') \ln |\vec\theta-\vec\theta'| d^2\vec\theta' \]
%
In particular we want
%
\[\sum_n \kappa_n Q_n(\vec\theta)\]
%
where $Q_n$ is the logarithm evaluated over the $n$th pixel at position $\vec\theta_n = (x_n, y_n)$. Let the pixel side length be $a$.
Instead of working with a position vector $\vec\theta$ we work in cartesian coordinates such that
%
$|\vec\theta| = r = \sqrt{x^2 + y^2}$. The integral now becomes
%
\[Q_n(x,y) = \frac12 \int_{y_-}^{y_+}\int_{x_-}^{x_+} \ln (x'^2+y'^2) dx' dy'\]
%
where $x_\pm = x + x_n \pm (a/2)$ and similarly for $y_\pm$.
Using the identity
%
\[\int \ln(x^2+y^2) dx = x \ln(x^2+y^2) - 2x + 2y\arctan(x/a) \]
%
we can express $Q_n$ as the sum of four parts
%
\[Q_n(x,y) = \frac12 \left[ \tilde Q_n(x_+,y_+)
        + \tilde Q_n(x_-,y_-)
        - \tilde Q_n(x_-,y_+)
        - \tilde Q_n(x_+,y_-) \right]\]
%
where
%
\[\tilde Q_n(x,y) = xy(\ln r^2 - 3) + x^2\arctan(y/x) + y^2\arctan(x/y)\]

\bibliographystyle{mn2e}
\bibliography{ms}

\end{document}

